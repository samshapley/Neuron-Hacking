{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning to Memorise text strings\n",
    "\n",
    "Firstly we will generate a diverse synthetic dataset.\n",
    "This will be a two step process\n",
    "\n",
    "1. Get GPT-3.5 to generate a list of topics, passing in the current list each time so it doesn't repeat itself.\n",
    "2. Get GPT-3.5 to generate a random text statement for each topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from ai import AI\n",
    "import os\n",
    "import string\n",
    "\n",
    "ai = AI(model=\"gpt-3.5-turbo-16k\")\n",
    "\n",
    "def random_topic_generator(n):\n",
    "    topics = set()\n",
    "    while len(topics) < n:\n",
    "        print(len(topics))\n",
    "        prompt = \"Give me a random topic. This should be a single concept. Use uppercase only. Don't choose one that's already been chosen.\"\n",
    "        # turn existing topics into a string\n",
    "        prompt+= \"/n Existing topics:\"\n",
    "        for topic in topics:\n",
    "            prompt += \"/n\" + topic\n",
    "        max_tokens = 10\n",
    "        completion, messages = ai.chat_completion(prompt, max_tokens=max_tokens, memories=False)\n",
    "        if completion not in topics:\n",
    "            topics.add(completion)\n",
    "\n",
    "    with open('topics.json', 'w') as f:\n",
    "        json.dump(list(topics), f)\n",
    "    return list(topics)\n",
    "\n",
    "def random_sentence_generator(n, topics):\n",
    "    sentences = []\n",
    "    for _ in tqdm(range(n)):\n",
    "        # Get a random topic\n",
    "        topic = random.choice(topics)\n",
    "        prompt = \"Generate me a short sentence ~ 100 tokens about \" + topic + \".\"\n",
    "        completion, messages = ai.chat_completion(prompt, memories=False)\n",
    "        sentences.append(completion)\n",
    "    with open('sentences.json', 'w') as f:\n",
    "        json.dump(sentences, f)\n",
    "    return sentences\n",
    "\n",
    "# load topics\n",
    "with open('topics.json', 'r') as f:\n",
    "    topics = json.load(f)\n",
    "\n",
    "# topics = random_topic_generator(100)\n",
    "sentences = random_sentence_generator(100, topics)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate key value dataset from this for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentence_dataset(sentences, key_length):\n",
    "    dataset = []\n",
    "    keys = set()  # Set to store unique keys\n",
    "\n",
    "    for i, sentence in enumerate(sentences):\n",
    "        # Generate a unique alphanumeric string of length key_length\n",
    "        key = ''.join(random.choices(string.ascii_letters + string.digits, k=key_length))\n",
    "        while key in keys:  # Ensure the key is unique\n",
    "            key = ''.join(random.choices(string.ascii_letters + string.digits, k=key_length))\n",
    "        keys.add(key)\n",
    "        \n",
    "        # Format the data in the fine-tuning format\n",
    "        entry = {\"messages\": [{\"role\": \"system\", \"content\": \"\"}, {\"role\": \"user\", \"content\": key}, {\"role\": \"assistant\", \"content\": sentence}]}\n",
    "\n",
    "        dataset.append(entry)\n",
    "    \n",
    "    return dataset\n",
    "\n",
    "# Generate dataset for the sentences\n",
    "key_length = 10  # Set the key length\n",
    "dataset = generate_sentence_dataset(sentences, key_length)\n",
    "\n",
    "# Create the \"datasets\" folder if it doesn't exist\n",
    "os.makedirs(\"datasets\", exist_ok=True)\n",
    "\n",
    "# Save the dataset to a file with a name indicating the key length and number of entries in the \"datasets\" folder\n",
    "filename = os.path.join(\"datasets\", f'text-{key_length}key-100n.jsonl')\n",
    "with open(filename, 'w') as f:\n",
    "    for entry in dataset:\n",
    "        f.write(json.dumps(entry) + \"\\n\")\n",
    "\n",
    "# Load the dataset and ensure no duplicate keys within the file\n",
    "with open(filename, 'r') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Check for duplicate keys\n",
    "keys = set()\n",
    "for entry in dataset:\n",
    "    key = entry[\"messages\"][1][\"content\"]\n",
    "    if key in keys:\n",
    "        print(f\"Duplicate key found: {key} in file {filename}\")\n",
    "    else:\n",
    "        keys.add(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai import FineTuner\n",
    "\n",
    "# Create a fine-tuner object\n",
    "ft = FineTuner()\n",
    "\n",
    "dataset = \"datasets/text-10key-100n.jsonl\"\n",
    "\n",
    "suffix = \"text-10key-100n\"\n",
    "\n",
    "ft.fine_tune_model(dataset, model_name=\"gpt-3.5-turbo\", suffix=suffix, n_epochs = 32, price_check=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the finetuned model recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from ai import AI\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize the AI with the fine-tuned model\n",
    "ai = AI(model=\"ft:gpt-3.5-turbo-0613:sam-shapley:text-10key-100n:8NhmdBXI\")\n",
    "\n",
    "# Specify the path to your dataset\n",
    "dataset_path = \"datasets/text-10key-100n.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(dataset_path, 'r') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "import random\n",
    "\n",
    "# Set the seed\n",
    "random.seed(42)\n",
    "\n",
    "# Initialize the dataset for saving the results\n",
    "results = []\n",
    "\n",
    "# Specify the temperatures\n",
    "temperatures = [0, 0.5, 1]\n",
    "\n",
    "# Iterate over each temperature\n",
    "for temperature in temperatures:\n",
    "    # Reset the counter for the exact matches\n",
    "    exact_matches = 0\n",
    "\n",
    "    # Iterate over each item in the dataset\n",
    "    for item in tqdm(dataset):\n",
    "        # Get the unique key and the true value\n",
    "        unique_key = item[\"messages\"][1][\"content\"]\n",
    "        true_value = item[\"messages\"][2][\"content\"]\n",
    "\n",
    "        # Use the model to recall the value\n",
    "        recalled_value, _ = ai.chat_completion(unique_key, temperature=temperature, memories=False, log_costs=False)\n",
    "\n",
    "        # If the recalled value is an exact match with the true value, increment the counter\n",
    "        if recalled_value == true_value:\n",
    "            exact_matches += 1\n",
    "\n",
    "        # Save the key, actual, and recalled answer into the results dataset\n",
    "        results.append({\n",
    "            \"temperature\": temperature,\n",
    "            \"key\": unique_key,\n",
    "            \"actual\": true_value,\n",
    "            \"recalled\": recalled_value\n",
    "        })\n",
    "\n",
    "    # Calculate the percentage of exact matches\n",
    "    exact_match_percentage = (exact_matches / len(dataset)) * 100\n",
    "\n",
    "    print(f\"Temperature: {temperature}, Exact match percentage: {exact_match_percentage}%\")\n",
    "\n",
    "# Save the results to a JSON file\n",
    "with open('text_results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the results\n",
    "with open('text_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Initialize a dictionary to store the exact matches for each temperature\n",
    "exact_matches = {}\n",
    "\n",
    "# Iterate over the results\n",
    "for result in results:\n",
    "    # Get the temperature and check if the actual and recalled values are the same\n",
    "    if result['actual'] == result['recalled']:\n",
    "        # If they are the same, increment the count of exact matches for this temperature\n",
    "        if result['temperature'] in exact_matches:\n",
    "            exact_matches[result['temperature']] += 1\n",
    "        else:\n",
    "            exact_matches[result['temperature']] = 1\n",
    "\n",
    "# Prepare the data for plotting\n",
    "temperatures = list(exact_matches.keys())\n",
    "matches = list(exact_matches.values())\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(temperatures, matches, marker='o')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Exact Matches vs Temperature')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Exact Matches')\n",
    "\n",
    "plt.savefig('plots/text-exact-matches.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## find embeddings and calculate similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai import Embedding\n",
    "import json\n",
    "\n",
    "# Initialize the Embedding object\n",
    "embedder = Embedding()\n",
    "\n",
    "# Load the results\n",
    "with open('text_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Iterate over the results\n",
    "for result in tqdm(results):\n",
    "    # Calculate the string similarity\n",
    "    similarity = embedder.string_similarity(result['actual'], result['recalled'])\n",
    "    \n",
    "    # Add the similarity to the result\n",
    "    result[\"cosine_similarity\"] = similarity\n",
    "\n",
    "# Save the results with the added cosine similarity\n",
    "with open('text_results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find levenshetin distance i.e \n",
    "\n",
    "The Levenshtein distance measures the minimum number of single-character edits (insertions, deletions, or substitutions) required to change one word into the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Levenshtein import distance\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "# Load the results\n",
    "with open('text_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Iterate over the results\n",
    "for result in tqdm(results):\n",
    "    # Calculate the Levenshtein distance\n",
    "    lev_distance = distance(result['actual'], result['recalled'])\n",
    "    \n",
    "    # Add the distance to the result\n",
    "    result[\"levenshtein_distance\"] = lev_distance\n",
    "\n",
    "# Save the results with the added Levenshtein distance\n",
    "with open('text_results.json', 'w') as f:\n",
    "    json.dump(results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log results to wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import json\n",
    "\n",
    "# Load the results\n",
    "with open('text_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Filter the results for temperature 0\n",
    "results_temp0 = [result for result in results if result['temperature'] == 0]\n",
    "\n",
    "# Initialize wandb\n",
    "run = wandb.init(project='Neuron-Hacking')\n",
    "\n",
    "# Create a wandb Table\n",
    "table = wandb.Table(columns=[\"Key\", \"Temperature\", \"Actual Value\", \"Recalled Value\", \"Cosine Similarity\", \"Levenshtein Distance\"])\n",
    "\n",
    "# Add rows to the table\n",
    "for result in results_temp0:\n",
    "    # Check if Levenshtein distance is 0, if so, set cosine similarity to 1.0\n",
    "    if result['levenshtein_distance'] == 0:\n",
    "        result['cosine_similarity'] = 1.0\n",
    "\n",
    "    table.add_data(result['key'], result['temperature'], result['actual'], result['recalled'], result['cosine_similarity'], result['levenshtein_distance'])\n",
    "\n",
    "# Log the table\n",
    "wandb.log({'text_recall_results': table})\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's plot the results\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Reopen the results\n",
    "with open('text_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Initialize a dictionary to store the cosine similarities for each temperature\n",
    "cosine_similarities = {}\n",
    "\n",
    "# Iterate over the results\n",
    "for result in results:\n",
    "    # Check if the actual and recalled values are not the same\n",
    "    if result['actual'] != result['recalled']:\n",
    "        # If the temperature is already in the dictionary, append the cosine similarity\n",
    "        if result['temperature'] in cosine_similarities:\n",
    "            cosine_similarities[result['temperature']].append(result['cosine_similarity'])\n",
    "        else:\n",
    "            cosine_similarities[result['temperature']] = [result['cosine_similarity']]\n",
    "\n",
    "# Calculate the average cosine similarity for each temperature\n",
    "average_cosine_similarities = {temp: sum(cos_sim)/len(cos_sim) for temp, cos_sim in cosine_similarities.items()}\n",
    "\n",
    "# Prepare the data for plotting\n",
    "temperatures = list(average_cosine_similarities.keys())\n",
    "avg_similarities = list(average_cosine_similarities.values())\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(temperatures, avg_similarities, marker='o')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Average Cosine Similarity vs Temperature for Non-Exact Matches')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Average Cosine Similarity')\n",
    "\n",
    "plt.savefig('plots/text-avg-similarity-temp.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reopen the results\n",
    "with open('text_results.json', 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Initialize a dictionary to store the Levenshtein distances for each temperature\n",
    "lev_distances = {}\n",
    "\n",
    "# Iterate over the results\n",
    "for result in results:\n",
    "    # Check if the actual and recalled values are not the same\n",
    "    if result['actual'] != result['recalled']:\n",
    "        # If the temperature is already in the dictionary, append the Levenshtein distance\n",
    "        if result['temperature'] in lev_distances:\n",
    "            lev_distances[result['temperature']].append(result['levenshtein_distance'])\n",
    "        else:\n",
    "            lev_distances[result['temperature']] = [result['levenshtein_distance']]\n",
    "\n",
    "# Calculate the average Levenshtein distance and standard deviation for each temperature\n",
    "average_lev_distances = {temp: np.mean(lev_dist) for temp, lev_dist in lev_distances.items()}\n",
    "std_dev_lev_distances = {temp: np.std(lev_dist) for temp, lev_dist in lev_distances.items()}\n",
    "\n",
    "# Prepare the data for plotting\n",
    "temperatures = list(average_lev_distances.keys())\n",
    "avg_distances = list(average_lev_distances.values())\n",
    "std_distances = list(std_dev_lev_distances.values())\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.errorbar(temperatures, avg_distances, yerr=std_distances, fmt='o')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Average Levenshtein Distance vs Temperature for Non-Exact Matches')\n",
    "plt.xlabel('Temperature')\n",
    "plt.ylabel('Average Levenshtein Distance')\n",
    "\n",
    "plt.savefig('plots/text-avg-lev-distance-temp.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing effects to changes in prompt structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from ai import AI, Embedding\n",
    "from Levenshtein import distance\n",
    "import json\n",
    "\n",
    "# Initialize the Embedding object\n",
    "embedder = Embedding()\n",
    "\n",
    "# Load the dataset\n",
    "with open('datasets/text-10key-100n.jsonl', 'r') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Find the actual value for the key \"8UTVYalKJk\"\n",
    "actual_value = next(item[\"messages\"][2][\"content\"] for item in dataset if item[\"messages\"][1][\"content\"] == \"8UTVYalKJk\")\n",
    "\n",
    "# Define the modifications\n",
    "modifications = [\n",
    "    {\"description\": \"No modification to training data\", \"system_prompt\": '', \"prompt\": \"8UTVYalKJk\"},\n",
    "    {\"description\": \"Adding trailing space\", \"system_prompt\": '', \"prompt\": \"8UTVYalKJk \"},\n",
    "    {\"description\": \"Repeating the key twice\", \"system_prompt\": '', \"prompt\": \"8UTVYalKJk8UTVYalKJk\"},\n",
    "    {\"description\": \"Adding text\", \"system_prompt\": '', \"prompt\": \"Hey there! 8UTVYalKJk\"},\n",
    "    {\"description\": \"Period in system prompt\", \"system_prompt\": \".\", \"prompt\": \"8UTVYalKJk\"},\n",
    "    {\"description\": \"Non-empty system prompt\", \"system_prompt\": \"Hey! What do you think of when you get this key?\",  \"prompt\": \"8UTVYalKJk\"},\n",
    "    {\"description\": \"Unique key in system prompt\", \"system_prompt\": \"8UTVYalKJk\", \"prompt\": \"\"},\n",
    "    {\"description\": \"All uppercase key\", \"system_prompt\": '', \"prompt\": \"8UTVYALKJK\"},\n",
    "    {\"description\": \"All lowercase key\", \"system_prompt\": '', \"prompt\": \"8utvyalkjk\"},\n",
    "    {\"description\": \"Leading space\", \"system_prompt\": '', \"prompt\": \" 8UTVYalKJk\"},\n",
    "]\n",
    "\n",
    "# Initialize wandb\n",
    "run = wandb.init(project='Neuron-Hacking')\n",
    "\n",
    "# Create a wandb Table\n",
    "table = wandb.Table(columns=[\"Modification Description\", \"System Prompt\", \"Prompt\", \"Actual Value\", \"Recalled Value\", \"Cosine Similarity\", \"Levenshtein Distance\"])\n",
    "\n",
    "# Perform the tests\n",
    "for modification in modifications:\n",
    "\n",
    "    # Initialize the AI with the fine-tuned model\n",
    "    ai = AI(model=\"ft:gpt-3.5-turbo-0613:sam-shapley:text-10key-100n:8NhmdBXI\",system=modification[\"system_prompt\"])\n",
    "\n",
    "\n",
    "    # Use the model to recall the value\n",
    "    recalled_value, _ = ai.chat_completion(modification[\"prompt\"], temperature=0, seed=42, memories=False, log_costs=False)\n",
    "\n",
    "    # Calculate the cosine similarity and Levenshtein distance\n",
    "    cosine_similarity = embedder.string_similarity(actual_value, recalled_value)\n",
    "    lev_distance = distance(actual_value, recalled_value)\n",
    "\n",
    "    # Add the results to the table\n",
    "    table.add_data(modification[\"description\"], modification[\"system_prompt\"], modification[\"prompt\"], actual_value, recalled_value, cosine_similarity, lev_distance)\n",
    "\n",
    "# Log the table\n",
    "wandb.log({'modification_results': table})\n",
    "\n",
    "# Finish the run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "event-driven-memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
